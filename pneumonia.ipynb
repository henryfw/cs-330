{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Single Class Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3999)])\n",
    " \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-25452c320fbf>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is your GPU available for use?\n",
      "Yes, your GPU is available: True\n",
      "\n",
      "Your devices that are available:\n",
      "['/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:GPU:0', '/physical_device:XLA_GPU:0']\n"
     ]
    }
   ],
   "source": [
    "print(('Is your GPU available for use?\\n{0}').format(\n",
    "    'Yes, your GPU is available: True' if tf.test.is_gpu_available() == True else 'No, your GPU is NOT available: False'\n",
    "))\n",
    "\n",
    "print(('\\nYour devices that are available:\\n{0}').format(\n",
    "    [device.name for device in tf.config.experimental.list_physical_devices()]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:55.975638Z",
     "iopub.status.busy": "2020-10-08T01:22:55.974545Z",
     "iopub.status.idle": "2020-10-08T01:22:56.930680Z",
     "shell.execute_reply": "2020-10-08T01:22:56.931142Z"
    },
    "id": "JqFRS6K07jJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4684, test size: 1172\n"
     ]
    }
   ],
   "source": [
    "raw_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/pneumonia-256-grayscale\", \"rb\" ) ) # array of tuples( [x,y], 0|1 )\n",
    "random.shuffle(raw_data)\n",
    "\n",
    "\n",
    "fraction_train = 0.8\n",
    "train_size = int(len(raw_data) * fraction_train)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for v in raw_data[0: train_size] :\n",
    "    x_train.append(v[0])\n",
    "    y_train.append(v[1])\n",
    "\n",
    "x_train = np.array(x_train) \n",
    "y_train = np.array(y_train)    \n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "for v in raw_data[train_size:]:\n",
    "    x_test.append(v[0])\n",
    "    y_test.append(v[1])\n",
    "    \n",
    "\n",
    "x_test = np.array(x_test) \n",
    "y_test = np.array(y_test)  \n",
    "\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "print(\"train size: {}, test size: {}\".format(len(x_train), len(x_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1Evqx0S22r_"
   },
   "source": [
    "Use `tf.data` to batch and shuffle the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.364209Z",
     "iopub.status.busy": "2020-10-08T01:23:04.363416Z",
     "iopub.status.idle": "2020-10-08T01:23:04.387872Z",
     "shell.execute_reply": "2020-10-08T01:23:04.388252Z"
    },
    "id": "8Iu_quO024c2"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(100).batch(8)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.395483Z",
     "iopub.status.busy": "2020-10-08T01:23:04.394652Z",
     "iopub.status.idle": "2020-10-08T01:23:04.689865Z",
     "shell.execute_reply": "2020-10-08T01:23:04.690256Z"
    },
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(64, activation='relu')\n",
    "    self.d2 = Dense(2)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGih-c2LgbJu"
   },
   "source": [
    "Choose an optimizer and loss function for training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.697138Z",
     "iopub.status.busy": "2020-10-08T01:23:04.696529Z",
     "iopub.status.idle": "2020-10-08T01:23:04.698387Z",
     "shell.execute_reply": "2020-10-08T01:23:04.698787Z"
    },
    "id": "u48C9WQ774n4"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB6A1vcigsIe"
   },
   "source": [
    "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.708701Z",
     "iopub.status.busy": "2020-10-08T01:23:04.708038Z",
     "iopub.status.idle": "2020-10-08T01:23:04.731817Z",
     "shell.execute_reply": "2020-10-08T01:23:04.732252Z"
    },
    "id": "N0MqHFb4F_qn"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix4mEL65on-w"
   },
   "source": [
    "Use `tf.GradientTape` to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.738604Z",
     "iopub.status.busy": "2020-10-08T01:23:04.737924Z",
     "iopub.status.idle": "2020-10-08T01:23:04.739923Z",
     "shell.execute_reply": "2020-10-08T01:23:04.739425Z"
    },
    "id": "OZACiVqA8KQV"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8YT7UmFgpjV"
   },
   "source": [
    "Test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.744781Z",
     "iopub.status.busy": "2020-10-08T01:23:04.744084Z",
     "iopub.status.idle": "2020-10-08T01:23:04.745839Z",
     "shell.execute_reply": "2020-10-08T01:23:04.746244Z"
    },
    "id": "xIKdEzHAJGt7"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.751851Z",
     "iopub.status.busy": "2020-10-08T01:23:04.751182Z",
     "iopub.status.idle": "2020-10-08T01:23:20.841977Z",
     "shell.execute_reply": "2020-10-08T01:23:20.841365Z"
    },
    "id": "i-2pkctU_Ci7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,  Loss: 0.9009949564933777,  Accuracy: 90.5636215209961,  Test Loss: 0.1885051429271698,  Test Accuracy: 92.32081604003906\n",
      "Epoch 2,  Loss: 0.09892739355564117,  Accuracy: 96.49871826171875,  Test Loss: 0.13723745942115784,  Test Accuracy: 95.30716705322266\n",
      "Epoch 3,  Loss: 0.05689525231719017,  Accuracy: 98.2280044555664,  Test Loss: 0.16288377344608307,  Test Accuracy: 94.19795227050781\n",
      "Epoch 4,  Loss: 0.06555783748626709,  Accuracy: 98.07856750488281,  Test Loss: 0.24839214980602264,  Test Accuracy: 91.46757507324219\n",
      "Epoch 5,  Loss: 0.08615981787443161,  Accuracy: 97.30998992919922,  Test Loss: 0.18826012313365936,  Test Accuracy: 93.94197845458984\n",
      "Epoch 6,  Loss: 0.013588440604507923,  Accuracy: 99.70111083984375,  Test Loss: 0.22355931997299194,  Test Accuracy: 94.36859893798828\n",
      "Epoch 7,  Loss: 0.0026017113123089075,  Accuracy: 99.97865295410156,  Test Loss: 0.3269086480140686,  Test Accuracy: 92.57678985595703\n",
      "Epoch 8,  Loss: 0.0007280330755747855,  Accuracy: 100.0,  Test Loss: 0.251067578792572,  Test Accuracy: 94.36859893798828\n",
      "Epoch 9,  Loss: 0.00018053398525808007,  Accuracy: 100.0,  Test Loss: 0.26374340057373047,  Test Accuracy: 94.36859893798828\n",
      "Epoch 10,  Loss: 6.111215043347329e-05,  Accuracy: 100.0,  Test Loss: 0.2830715477466583,  Test Accuracy: 94.36859893798828\n",
      "Epoch 11,  Loss: 3.2795476727187634e-05,  Accuracy: 100.0,  Test Loss: 0.2983134388923645,  Test Accuracy: 94.28327941894531\n",
      "Epoch 12,  Loss: 2.0912240870529786e-05,  Accuracy: 100.0,  Test Loss: 0.31083688139915466,  Test Accuracy: 94.19795227050781\n",
      "Epoch 13,  Loss: 1.418974352418445e-05,  Accuracy: 100.0,  Test Loss: 0.31773024797439575,  Test Accuracy: 94.11262512207031\n",
      "Epoch 14,  Loss: 9.875146133708768e-06,  Accuracy: 100.0,  Test Loss: 0.32442015409469604,  Test Accuracy: 94.19795227050781\n",
      "Epoch 15,  Loss: 6.998296157689765e-06,  Accuracy: 100.0,  Test Loss: 0.33187875151634216,  Test Accuracy: 94.28327941894531\n",
      "Epoch 16,  Loss: 5.329938630893594e-06,  Accuracy: 100.0,  Test Loss: 0.3396151661872864,  Test Accuracy: 94.36859893798828\n",
      "Epoch 17,  Loss: 3.9139108594099525e-06,  Accuracy: 100.0,  Test Loss: 0.34433338046073914,  Test Accuracy: 94.36859893798828\n",
      "Epoch 18,  Loss: 2.967594582514721e-06,  Accuracy: 100.0,  Test Loss: 0.35169729590415955,  Test Accuracy: 94.36859893798828\n",
      "Epoch 19,  Loss: 2.2080801045376575e-06,  Accuracy: 100.0,  Test Loss: 0.3566889464855194,  Test Accuracy: 94.45392608642578\n",
      "Epoch 20,  Loss: 1.7009730299832881e-06,  Accuracy: 100.0,  Test Loss: 0.36180052161216736,  Test Accuracy: 94.45392608642578\n",
      "Epoch 21,  Loss: 1.3117731896272744e-06,  Accuracy: 100.0,  Test Loss: 0.3691473603248596,  Test Accuracy: 94.62457275390625\n",
      "Epoch 22,  Loss: 1.0067110451927874e-06,  Accuracy: 100.0,  Test Loss: 0.37384527921676636,  Test Accuracy: 94.53924560546875\n",
      "Epoch 23,  Loss: 8.284337127406616e-07,  Accuracy: 100.0,  Test Loss: 0.38055387139320374,  Test Accuracy: 94.53924560546875\n",
      "Epoch 24,  Loss: 6.040032189957856e-07,  Accuracy: 100.0,  Test Loss: 0.3882271945476532,  Test Accuracy: 94.70989990234375\n",
      "Epoch 25,  Loss: 5.265728191261587e-07,  Accuracy: 100.0,  Test Loss: 0.39275291562080383,  Test Accuracy: 94.53924560546875\n",
      "Epoch 26,  Loss: 3.8447959127552167e-07,  Accuracy: 100.0,  Test Loss: 0.4017174243927002,  Test Accuracy: 94.70989990234375\n",
      "Epoch 27,  Loss: 2.90801040137012e-07,  Accuracy: 100.0,  Test Loss: 0.41072916984558105,  Test Accuracy: 94.79521942138672\n",
      "Epoch 28,  Loss: 2.6410089049022645e-07,  Accuracy: 100.0,  Test Loss: 0.40919229388237,  Test Accuracy: 94.70989990234375\n",
      "Epoch 29,  Loss: 2.2799210341872822e-07,  Accuracy: 100.0,  Test Loss: 0.4144105017185211,  Test Accuracy: 94.62457275390625\n",
      "Epoch 30,  Loss: 1.4430720796099195e-07,  Accuracy: 100.0,  Test Loss: 0.4209347367286682,  Test Accuracy: 94.62457275390625\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    'Epoch {}, '.format(epoch + 1),\n",
    "    'Loss: {}, '.format(train_loss.result()),\n",
    "    'Accuracy: {}, '.format(train_accuracy.result() * 100),\n",
    "    'Test Loss: {}, '.format(test_loss.result()),\n",
    "    'Test Accuracy: {}'.format(test_accuracy.result() * 100)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[243  39]\n",
      " [ 24 866]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(x_test)\n",
    "predictions = tf.argmax(predictions, axis=1)\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test, predictions, 2)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
