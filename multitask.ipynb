{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Multiple Task Pneumonia & TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:49.877792Z",
     "iopub.status.busy": "2020-10-08T01:22:49.877115Z",
     "iopub.status.idle": "2020-10-08T01:22:55.969522Z",
     "shell.execute_reply": "2020-10-08T01:22:55.968963Z"
    },
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3999)])\n",
    " \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-25452c320fbf>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is your GPU available for use?\n",
      "Yes, your GPU is available: True\n",
      "\n",
      "Your devices that are available:\n",
      "['/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:GPU:0', '/physical_device:XLA_GPU:0']\n"
     ]
    }
   ],
   "source": [
    "print(('Is your GPU available for use?\\n{0}').format(\n",
    "    'Yes, your GPU is available: True' if tf.test.is_gpu_available() == True else 'No, your GPU is NOT available: False'\n",
    "))\n",
    "\n",
    "print(('\\nYour devices that are available:\\n{0}').format(\n",
    "    [device.name for device in tf.config.experimental.list_physical_devices()]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:55.975638Z",
     "iopub.status.busy": "2020-10-08T01:22:55.974545Z",
     "iopub.status.idle": "2020-10-08T01:22:56.930680Z",
     "shell.execute_reply": "2020-10-08T01:22:56.931142Z"
    },
    "id": "JqFRS6K07jJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 5214, test size: 1304\n",
      "tb1_data size: 662, p_data size: 5856\n"
     ]
    }
   ],
   "source": [
    "tb1_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/tb1-256-grayscale\", \"rb\" ) )\n",
    "\n",
    "p_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/pneumonia-256-grayscale\", \"rb\" ) )\n",
    " \n",
    "# duplicate to have equal amounts\n",
    "# for i in range(3):\n",
    "#     tb1_data = tb1_data + tb1_data\n",
    "\n",
    "x_data = []\n",
    "y_data_tb1 = []\n",
    "y_data_p = []\n",
    "indices_map = [] # true is tb1\n",
    "\n",
    "for v in tb1_data:\n",
    "    x_data.append( v[0] )\n",
    "    y_data_tb1.append(v[1])\n",
    "    y_data_p.append(0)\n",
    "    indices_map.append(1)\n",
    "    \n",
    "\n",
    "for v in p_data:\n",
    "    x_data.append( v[0] )\n",
    "    y_data_tb1.append(0)\n",
    "    y_data_p.append(v[1])\n",
    "    indices_map.append(0)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data_tb1 = np.array(y_data_tb1)\n",
    "y_data_p = np.array(y_data_p)\n",
    "indices_map = np.array(indices_map)\n",
    "\n",
    "s = np.arange(len(x_data))\n",
    "np.random.shuffle(s)\n",
    "\n",
    " \n",
    "x_data = x_data[s]\n",
    "y_data_tb1 = y_data_tb1[s]\n",
    "y_data_p = y_data_p[s]\n",
    "\n",
    "\n",
    "fraction_train = 0.8\n",
    "train_size = int(len(x_data) * fraction_train)\n",
    "\n",
    "x_train = x_data[0: train_size]/ 255.0\n",
    "y_train_tb1 = y_data_tb1[0: train_size]\n",
    "y_train_p = y_data_p[0: train_size]\n",
    "\n",
    "\n",
    "\n",
    "x_test = np.array(x_data[train_size:]) / 255.0\n",
    "y_test_tb1 = np.array(y_data_tb1[train_size:])\n",
    "y_test_p = np.array(y_data_p[train_size:])\n",
    "\n",
    "\n",
    "# which index are part of tb1\n",
    "indices_test_map = np.array( indices_map[s] )[train_size:]\n",
    "indices_test_tb1 = np.argwhere( indices_test_map == 1 ).flatten()\n",
    "indices_test_p = np.argwhere( indices_test_map == 0 ).flatten()\n",
    "\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "\n",
    "print(\"Train size: {}, test size: {}\".format(len(x_train), len(x_test)))\n",
    "\n",
    "print(\"tb1_data size: {}, p_data size: {}\".format(len(tb1_data), len(p_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.395483Z",
     "iopub.status.busy": "2020-10-08T01:23:04.394652Z",
     "iopub.status.idle": "2020-10-08T01:23:04.689865Z",
     "shell.execute_reply": "2020-10-08T01:23:04.690256Z"
    },
    "id": "h3IKyzTCDNGo",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/652 [..............................] - ETA: 34s - loss: 42.7622 - tb1_accuracy: 0.5000 - pneumonia_accuracy: 0.4375 - pneumonia_loss: 42.3933 - tb1_loss: 0.3689 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0310s vs `on_train_batch_end` time: 0.0750s). Check your callbacks.\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 1.5957 - tb1_accuracy: 0.9593 - pneumonia_accuracy: 0.7618 - pneumonia_loss: 0.9309 - tb1_loss: 0.6648\n",
      "Epoch 2/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.3065 - tb1_accuracy: 0.9772 - pneumonia_accuracy: 0.9390 - pneumonia_loss: 0.2432 - tb1_loss: 0.0633\n",
      "Epoch 3/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.2030 - tb1_accuracy: 0.9841 - pneumonia_accuracy: 0.9620 - pneumonia_loss: 0.1601 - tb1_loss: 0.0428\n",
      "Epoch 4/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.1466 - tb1_accuracy: 0.9895 - pneumonia_accuracy: 0.9724 - pneumonia_loss: 0.1153 - tb1_loss: 0.0313\n",
      "Epoch 5/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.1230 - tb1_accuracy: 0.9908 - pneumonia_accuracy: 0.9735 - pneumonia_loss: 0.0967 - tb1_loss: 0.0263\n",
      "Epoch 6/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.1515 - tb1_accuracy: 0.9921 - pneumonia_accuracy: 0.9574 - pneumonia_loss: 0.1126 - tb1_loss: 0.0389\n",
      "Epoch 7/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.0696 - tb1_accuracy: 0.9975 - pneumonia_accuracy: 0.9799 - pneumonia_loss: 0.0597 - tb1_loss: 0.0099\n",
      "Epoch 8/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.0136 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9964 - pneumonia_loss: 0.0124 - tb1_loss: 0.0011\n",
      "Epoch 9/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.0037 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9994 - pneumonia_loss: 0.0035 - tb1_loss: 2.0178e-04\n",
      "Epoch 10/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 9.1751e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 8.5137e-04 - tb1_loss: 6.6142e-05\n",
      "Epoch 11/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 9.5419e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 8.9809e-04 - tb1_loss: 5.6107e-05\n",
      "Epoch 12/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 6.0499e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 5.8469e-04 - tb1_loss: 2.0305e-05\n",
      "Epoch 13/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 4.9609e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 4.8354e-04 - tb1_loss: 1.2553e-05\n",
      "Epoch 14/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 4.5603e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 4.4825e-04 - tb1_loss: 7.7764e-06\n",
      "Epoch 15/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 4.5282e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 4.4345e-04 - tb1_loss: 9.3650e-06\n",
      "Epoch 16/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 4.3330e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 4.2951e-04 - tb1_loss: 3.7921e-06\n",
      "Epoch 17/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 4.2080e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 0.9998 - pneumonia_loss: 4.1844e-04 - tb1_loss: 2.3555e-06\n",
      "Epoch 18/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.1062 - tb1_accuracy: 0.9964 - pneumonia_accuracy: 0.9891 - pneumonia_loss: 0.0565 - tb1_loss: 0.0497\n",
      "Epoch 19/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.0510 - tb1_accuracy: 0.9965 - pneumonia_accuracy: 0.9883 - pneumonia_loss: 0.0394 - tb1_loss: 0.0117\n",
      "Epoch 20/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 0.0069 - tb1_accuracy: 0.9992 - pneumonia_accuracy: 0.9994 - pneumonia_loss: 0.0041 - tb1_loss: 0.0027\n",
      "Epoch 21/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 9.4078e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 8.1073e-04 - tb1_loss: 1.3005e-04\n",
      "Epoch 22/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 2.4702e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 2.1061e-04 - tb1_loss: 3.6412e-05\n",
      "Epoch 23/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 1.2871e-04 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 1.0633e-04 - tb1_loss: 2.2372e-05\n",
      "Epoch 24/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 8.0284e-05 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 6.5682e-05 - tb1_loss: 1.4601e-05\n",
      "Epoch 25/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 5.2502e-05 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 4.2258e-05 - tb1_loss: 1.0244e-05\n",
      "Epoch 26/30\n",
      "652/652 [==============================] - 64s 99ms/step - loss: 3.5702e-05 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 2.8670e-05 - tb1_loss: 7.0321e-06\n",
      "Epoch 27/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 2.3773e-05 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 1.8879e-05 - tb1_loss: 4.8947e-06\n",
      "Epoch 28/30\n",
      "652/652 [==============================] - 64s 99ms/step - loss: 1.7537e-05 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 1.3834e-05 - tb1_loss: 3.7021e-06\n",
      "Epoch 29/30\n",
      "652/652 [==============================] - 64s 99ms/step - loss: 1.1638e-05 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 9.0347e-06 - tb1_loss: 2.6035e-06\n",
      "Epoch 30/30\n",
      "652/652 [==============================] - 64s 98ms/step - loss: 8.5693e-06 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 6.4887e-06 - tb1_loss: 2.0806e-06\n",
      "Evaluation: \n",
      "['loss', 'tb1_loss', 'pneumonia_loss', 'tb1_accuracy', 'pneumonia_accuracy']\n",
      "  1/163 [..............................] - ETA: 4s - loss: 1.3560e-06 - tb1_accuracy: 1.0000 - pneumonia_accuracy: 1.0000 - pneumonia_loss: 1.3560e-06 - tb1_loss: 0.0000e+00WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0250s). Check your callbacks.\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.5614 - tb1_accuracy: 0.9739 - pneumonia_accuracy: 0.9463 - pneumonia_loss: 0.3231 - tb1_loss: 0.2383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5614321827888489,\n",
       " 0.23830507695674896,\n",
       " 0.32312706112861633,\n",
       " 0.9739263653755188,\n",
       " 0.946319043636322]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_input = Input(shape=(256, 256, 1))\n",
    "shared = Conv2D(32, 3, activation='relu')(model_input)\n",
    "shared = Flatten()(shared)\n",
    "y1 = Dense(64, activation='relu')(shared)\n",
    "y1 = Dense(2, name='tb1')(y1)\n",
    "\n",
    "y2 = Dense(64, activation='relu')(shared)\n",
    "y2 = Dense(2, name='pneumonia')(y2)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "\n",
    "loss_list =[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)]\n",
    "test_metrics = {'tb1': 'accuracy', 'pneumonia': 'accuracy' }\n",
    "model.compile(loss=loss_list,optimizer='adam',metrics=test_metrics)\n",
    "\n",
    "\n",
    "model.fit(x_train, [y_train_tb1, y_train_p], batch_size=8, epochs=30)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluation: \")\n",
    "print(model.metrics_names)\n",
    "\n",
    "model.evaluate(x_test, [y_test_tb1, y_test_p], batch_size=8)\n",
    "\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[68  1]\n",
      " [ 2 77]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[334   4]\n",
      " [  6 812]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions_tb1 = np.array(tf.argmax(predictions[0], axis=1))\n",
    "predictions_p = np.array(tf.argmax(predictions[1], axis=1))\n",
    "\n",
    "# only look at indices for ones with relevant data  \n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test_tb1[indices_test_tb1], predictions_tb1[indices_test_tb1], 2)\n",
    "print(cm)\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test_p[indices_test_p], predictions_p[indices_test_p], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
