{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Multiple Task Pneumonia & TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:49.877792Z",
     "iopub.status.busy": "2020-10-08T01:22:49.877115Z",
     "iopub.status.idle": "2020-10-08T01:22:55.969522Z",
     "shell.execute_reply": "2020-10-08T01:22:55.968963Z"
    },
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3999)])\n",
    " \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-25452c320fbf>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is your GPU available for use?\n",
      "Yes, your GPU is available: True\n",
      "\n",
      "Your devices that are available:\n",
      "['/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:GPU:0', '/physical_device:XLA_GPU:0']\n"
     ]
    }
   ],
   "source": [
    "print(('Is your GPU available for use?\\n{0}').format(\n",
    "    'Yes, your GPU is available: True' if tf.test.is_gpu_available() == True else 'No, your GPU is NOT available: False'\n",
    "))\n",
    "\n",
    "print(('\\nYour devices that are available:\\n{0}').format(\n",
    "    [device.name for device in tf.config.experimental.list_physical_devices()]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:55.975638Z",
     "iopub.status.busy": "2020-10-08T01:22:55.974545Z",
     "iopub.status.idle": "2020-10-08T01:22:56.930680Z",
     "shell.execute_reply": "2020-10-08T01:22:56.931142Z"
    },
    "id": "JqFRS6K07jJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 5214, test size: 1304\n",
      "tb1_data size: 662, p_data size: 5856\n"
     ]
    }
   ],
   "source": [
    "tb1_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/tb1-256-grayscale\", \"rb\" ) )\n",
    "\n",
    "p_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/pneumonia-256-grayscale\", \"rb\" ) )\n",
    " \n",
    "# duplicate to have equal amounts\n",
    "# for i in range(3):\n",
    "#     tb1_data = tb1_data + tb1_data\n",
    "\n",
    "x_data = []\n",
    "y_data_tb1 = []\n",
    "y_data_p = []\n",
    "indices_map = [] # true is tb1\n",
    "\n",
    "for v in tb1_data:\n",
    "    x_data.append( v[0] )\n",
    "    y_data_tb1.append(v[1])\n",
    "    y_data_p.append(0)\n",
    "    indices_map.append(1)\n",
    "    \n",
    "\n",
    "for v in p_data:\n",
    "    x_data.append( v[0] )\n",
    "    y_data_tb1.append(0)\n",
    "    y_data_p.append(v[1])\n",
    "    indices_map.append(0)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data_tb1 = np.array(y_data_tb1)\n",
    "y_data_p = np.array(y_data_p)\n",
    "indices_map = np.array(indices_map)\n",
    "\n",
    "s = np.arange(len(x_data))\n",
    "np.random.shuffle(s)\n",
    "\n",
    " \n",
    "x_data = x_data[s]\n",
    "y_data_tb1 = y_data_tb1[s]\n",
    "y_data_p = y_data_p[s]\n",
    "\n",
    "\n",
    "fraction_train = 0.8\n",
    "train_size = int(len(x_data) * fraction_train)\n",
    "\n",
    "x_train = x_data[0: train_size]/ 255.0\n",
    "y_train_tb1 = y_data_tb1[0: train_size]\n",
    "y_train_p = y_data_p[0: train_size]\n",
    "\n",
    "\n",
    "\n",
    "x_test = np.array(x_data[train_size:]) / 255.0\n",
    "y_test_tb1 = np.array(y_data_tb1[train_size:])\n",
    "y_test_p = np.array(y_data_p[train_size:])\n",
    "\n",
    "\n",
    "# which index are part of tb1\n",
    "indices_test_map = np.array( indices_map[s] )[train_size:]\n",
    "indices_test_tb1 = np.argwhere( indices_test_map == 1 ).flatten()\n",
    "indices_test_p = np.argwhere( indices_test_map == 0 ).flatten()\n",
    "\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "\n",
    "print(\"Train size: {}, test size: {}\".format(len(x_train), len(x_test)))\n",
    "\n",
    "print(\"tb1_data size: {}, p_data size: {}\".format(len(tb1_data), len(p_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.395483Z",
     "iopub.status.busy": "2020-10-08T01:23:04.394652Z",
     "iopub.status.idle": "2020-10-08T01:23:04.689865Z",
     "shell.execute_reply": "2020-10-08T01:23:04.690256Z"
    },
    "id": "h3IKyzTCDNGo",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/652 [..............................] - ETA: 22s - tb1_loss: 0.3131 - pneumonia_accuracy: 0.6250 - tb1_accuracy: 1.0000 - loss: 16.2068 - pneumonia_loss: 15.8937WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0270s vs `on_train_batch_end` time: 0.0410s). Check your callbacks.\n",
      "652/652 [==============================] - 45s 68ms/step - tb1_loss: 0.9636 - pneumonia_accuracy: 0.8980 - tb1_accuracy: 0.9404 - loss: 1.3312 - pneumonia_loss: 0.3677\n",
      "Epoch 2/30\n",
      "652/652 [==============================] - 45s 69ms/step - tb1_loss: 0.0839 - pneumonia_accuracy: 0.9574 - tb1_accuracy: 0.9542 - loss: 0.2085 - pneumonia_loss: 0.1246\n",
      "Epoch 3/30\n",
      "652/652 [==============================] - 45s 69ms/step - tb1_loss: 0.0841 - pneumonia_accuracy: 0.9701 - tb1_accuracy: 0.9638 - loss: 0.1735 - pneumonia_loss: 0.0894\n",
      "Epoch 4/30\n",
      " 37/652 [>.............................] - ETA: 41s - tb1_loss: 0.0498 - pneumonia_accuracy: 0.9696 - tb1_accuracy: 0.9730 - loss: 0.1355 - pneumonia_loss: 0.0857"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_input = Input(shape=(256, 256, 1))\n",
    "shared = Conv2D(32, 3, activation='relu')(model_input)\n",
    "shared = Flatten()(shared)\n",
    "y1 = Dense(32, activation='relu')(shared)\n",
    "y1 = Dense(2, name='tb1')(y1)\n",
    "\n",
    "y2 = Dense(32, activation='relu')(shared)\n",
    "y2 = Dense(2, name='pneumonia')(y2)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "\n",
    "loss_list =[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)]\n",
    "test_metrics = {'tb1': 'accuracy', 'pneumonia': 'accuracy' }\n",
    "model.compile(loss=loss_list,optimizer='adam',metrics=test_metrics)\n",
    "\n",
    "\n",
    "model.fit(x_train, [y_train_tb1, y_train_p], batch_size=8, epochs=30)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluation: \")\n",
    "print(model.metrics_names)\n",
    "\n",
    "model.evaluate(x_test, [y_test_tb1, y_test_p], batch_size=8)\n",
    "\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions_tb1 = np.array(tf.argmax(predictions[0], axis=1))\n",
    "predictions_p = np.array(tf.argmax(predictions[1], axis=1))\n",
    "\n",
    "# only look at indices for ones with relevant data  \n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test_tb1[indices_test_tb1], predictions_tb1[indices_test_tb1], 2)\n",
    "print(cm)\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test_p[indices_test_p], predictions_p[indices_test_p], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
