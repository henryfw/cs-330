{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Multiple Task Pneumonia & TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:49.877792Z",
     "iopub.status.busy": "2020-10-08T01:22:49.877115Z",
     "iopub.status.idle": "2020-10-08T01:22:55.969522Z",
     "shell.execute_reply": "2020-10-08T01:22:55.968963Z"
    },
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3999)])\n",
    " \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-25452c320fbf>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is your GPU available for use?\n",
      "Yes, your GPU is available: True\n",
      "\n",
      "Your devices that are available:\n",
      "['/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:GPU:0', '/physical_device:XLA_GPU:0']\n"
     ]
    }
   ],
   "source": [
    "print(('Is your GPU available for use?\\n{0}').format(\n",
    "    'Yes, your GPU is available: True' if tf.test.is_gpu_available() == True else 'No, your GPU is NOT available: False'\n",
    "))\n",
    "\n",
    "print(('\\nYour devices that are available:\\n{0}').format(\n",
    "    [device.name for device in tf.config.experimental.list_physical_devices()]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:22:55.975638Z",
     "iopub.status.busy": "2020-10-08T01:22:55.974545Z",
     "iopub.status.idle": "2020-10-08T01:22:56.930680Z",
     "shell.execute_reply": "2020-10-08T01:22:56.931142Z"
    },
    "id": "JqFRS6K07jJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 5214, test size: 1304\n",
      "tb1_data size: 662, p_data size: 5856\n"
     ]
    }
   ],
   "source": [
    "tb1_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/tb1-256-grayscale\", \"rb\" ) )\n",
    "\n",
    "p_data = pickle.load( open( \"C:/Users/uprz2/Downloads/cs330/data/pneumonia-256-grayscale\", \"rb\" ) )\n",
    " \n",
    "# duplicate to have equal amounts\n",
    "# for i in range(3):\n",
    "#     tb1_data = tb1_data + tb1_data\n",
    "\n",
    "x_data = []\n",
    "y_data_tb1 = []\n",
    "y_data_p = []\n",
    "indices_map = [] # true is tb1\n",
    "\n",
    "for v in tb1_data:\n",
    "    x_data.append( v[0] )\n",
    "    y_data_tb1.append(v[1])\n",
    "    y_data_p.append(0)\n",
    "    indices_map.append(1)\n",
    "    \n",
    "\n",
    "for v in p_data:\n",
    "    x_data.append( v[0] )\n",
    "    y_data_tb1.append(0)\n",
    "    y_data_p.append(v[1])\n",
    "    indices_map.append(0)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data_tb1 = np.array(y_data_tb1)\n",
    "y_data_p = np.array(y_data_p)\n",
    "indices_map = np.array(indices_map)\n",
    "\n",
    "s = np.arange(len(x_data))\n",
    "np.random.shuffle(s)\n",
    "\n",
    " \n",
    "x_data = x_data[s]\n",
    "y_data_tb1 = y_data_tb1[s]\n",
    "y_data_p = y_data_p[s]\n",
    "\n",
    "\n",
    "fraction_train = 0.8\n",
    "train_size = int(len(x_data) * fraction_train)\n",
    "\n",
    "x_train = x_data[0: train_size]/ 255.0\n",
    "y_train_tb1 = y_data_tb1[0: train_size]\n",
    "y_train_p = y_data_p[0: train_size]\n",
    "\n",
    "\n",
    "\n",
    "x_test = np.array(x_data[train_size:]) / 255.0\n",
    "y_test_tb1 = np.array(y_data_tb1[train_size:])\n",
    "y_test_p = np.array(y_data_p[train_size:])\n",
    "\n",
    "\n",
    "# which index are part of tb1\n",
    "indices_test_map = np.array( indices_map[s] )[train_size:]\n",
    "indices_test_tb1 = np.argwhere( indices_test_map == 1 ).flatten()\n",
    "indices_test_p = np.argwhere( indices_test_map == 0 ).flatten()\n",
    "\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "\n",
    "print(\"Train size: {}, test size: {}\".format(len(x_train), len(x_test)))\n",
    "\n",
    "print(\"tb1_data size: {}, p_data size: {}\".format(len(tb1_data), len(p_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T01:23:04.395483Z",
     "iopub.status.busy": "2020-10-08T01:23:04.394652Z",
     "iopub.status.idle": "2020-10-08T01:23:04.689865Z",
     "shell.execute_reply": "2020-10-08T01:23:04.690256Z"
    },
    "id": "h3IKyzTCDNGo",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/652 [..............................] - ETA: 22s - pneumonia_loss: 19.6716 - pneumonia_accuracy: 0.8750 - loss: 20.0075 - tb1_loss: 0.3360 - tb1_accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0270s vs `on_train_batch_end` time: 0.0420s). Check your callbacks.\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.1116 - pneumonia_accuracy: 0.9062 - loss: 1.6497 - tb1_loss: 0.5381 - tb1_accuracy: 0.9488\n",
      "Epoch 2/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.1028 - pneumonia_accuracy: 0.9645 - loss: 0.1926 - tb1_loss: 0.0899 - tb1_accuracy: 0.9488\n",
      "Epoch 3/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.1095 - pneumonia_accuracy: 0.9605 - loss: 0.1892 - tb1_loss: 0.0797 - tb1_accuracy: 0.9488\n",
      "Epoch 4/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0619 - pneumonia_accuracy: 0.9808 - loss: 0.1424 - tb1_loss: 0.0805 - tb1_accuracy: 0.9488\n",
      "Epoch 5/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0878 - pneumonia_accuracy: 0.9810 - loss: 0.1937 - tb1_loss: 0.1059 - tb1_accuracy: 0.9607\n",
      "Epoch 6/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0303 - pneumonia_accuracy: 0.9914 - loss: 0.1115 - tb1_loss: 0.0812 - tb1_accuracy: 0.9655\n",
      "Epoch 7/30\n",
      "652/652 [==============================] - 45s 68ms/step - pneumonia_loss: 0.0537 - pneumonia_accuracy: 0.9845 - loss: 0.1278 - tb1_loss: 0.0741 - tb1_accuracy: 0.9657\n",
      "Epoch 8/30\n",
      "652/652 [==============================] - 45s 69ms/step - pneumonia_loss: 0.0174 - pneumonia_accuracy: 0.9942 - loss: 0.0751 - tb1_loss: 0.0576 - tb1_accuracy: 0.9735\n",
      "Epoch 9/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0046 - pneumonia_accuracy: 0.9990 - loss: 0.0570 - tb1_loss: 0.0524 - tb1_accuracy: 0.9793\n",
      "Epoch 10/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0415 - pneumonia_accuracy: 0.9906 - loss: 0.1008 - tb1_loss: 0.0593 - tb1_accuracy: 0.9783\n",
      "Epoch 11/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0592 - pneumonia_accuracy: 0.9908 - loss: 0.1054 - tb1_loss: 0.0462 - tb1_accuracy: 0.9837\n",
      "Epoch 12/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0071 - pneumonia_accuracy: 0.9983 - loss: 0.0323 - tb1_loss: 0.0252 - tb1_accuracy: 0.9919\n",
      "Epoch 13/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 8.1321e-04 - pneumonia_accuracy: 1.0000 - loss: 0.0146 - tb1_loss: 0.0138 - tb1_accuracy: 0.9962\n",
      "Epoch 14/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.9153e-04 - pneumonia_accuracy: 1.0000 - loss: 0.0062 - tb1_loss: 0.0060 - tb1_accuracy: 0.9981\n",
      "Epoch 15/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.1719e-04 - pneumonia_accuracy: 1.0000 - loss: 0.0018 - tb1_loss: 0.0017 - tb1_accuracy: 0.9994\n",
      "Epoch 16/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 2.7016e-04 - pneumonia_accuracy: 1.0000 - loss: 0.0014 - tb1_loss: 0.0011 - tb1_accuracy: 0.9996\n",
      "Epoch 17/30\n",
      "652/652 [==============================] - 45s 68ms/step - pneumonia_loss: 0.0419 - pneumonia_accuracy: 0.9877 - loss: 0.0572 - tb1_loss: 0.0153 - tb1_accuracy: 0.9950\n",
      "Epoch 18/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 0.0098 - pneumonia_accuracy: 0.9975 - loss: 0.0159 - tb1_loss: 0.0062 - tb1_accuracy: 0.9979\n",
      "Epoch 19/30\n",
      "652/652 [==============================] - 45s 68ms/step - pneumonia_loss: 0.0074 - pneumonia_accuracy: 0.9988 - loss: 0.0095 - tb1_loss: 0.0021 - tb1_accuracy: 0.9992\n",
      "Epoch 20/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.8917e-04 - pneumonia_accuracy: 1.0000 - loss: 3.3516e-04 - tb1_loss: 1.4599e-04 - tb1_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 6.6491e-05 - pneumonia_accuracy: 1.0000 - loss: 1.0261e-04 - tb1_loss: 3.6114e-05 - tb1_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 2.7610e-05 - pneumonia_accuracy: 1.0000 - loss: 4.7226e-05 - tb1_loss: 1.9617e-05 - tb1_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.6353e-05 - pneumonia_accuracy: 1.0000 - loss: 2.9586e-05 - tb1_loss: 1.3233e-05 - tb1_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 9.7431e-06 - pneumonia_accuracy: 1.0000 - loss: 1.8885e-05 - tb1_loss: 9.1415e-06 - tb1_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 6.1975e-06 - pneumonia_accuracy: 1.0000 - loss: 1.2480e-05 - tb1_loss: 6.2829e-06 - tb1_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 4.0361e-06 - pneumonia_accuracy: 1.0000 - loss: 8.5821e-06 - tb1_loss: 4.5460e-06 - tb1_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 2.7916e-06 - pneumonia_accuracy: 1.0000 - loss: 5.9641e-06 - tb1_loss: 3.1725e-06 - tb1_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 2.0085e-06 - pneumonia_accuracy: 1.0000 - loss: 4.2493e-06 - tb1_loss: 2.2407e-06 - tb1_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.4321e-06 - pneumonia_accuracy: 1.0000 - loss: 3.0834e-06 - tb1_loss: 1.6513e-06 - tb1_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "652/652 [==============================] - 44s 68ms/step - pneumonia_loss: 1.0192e-06 - pneumonia_accuracy: 1.0000 - loss: 2.2198e-06 - tb1_loss: 1.2006e-06 - tb1_accuracy: 1.0000\n",
      "Evaluation: \n",
      "['loss', 'tb1_loss', 'pneumonia_loss', 'tb1_accuracy', 'pneumonia_accuracy']\n",
      "  1/163 [..............................] - ETA: 3s - pneumonia_loss: 6.9963e-04 - pneumonia_accuracy: 1.0000 - loss: 0.0247 - tb1_loss: 0.0240 - tb1_accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0250s). Check your callbacks.\n",
      "163/163 [==============================] - 4s 27ms/step - pneumonia_loss: 0.6342 - pneumonia_accuracy: 0.9310 - loss: 0.7478 - tb1_loss: 0.1136 - tb1_accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7478324174880981,\n",
       " 0.11363428831100464,\n",
       " 0.6341978311538696,\n",
       " 0.9823619723320007,\n",
       " 0.9309815764427185]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_input = Input(shape=(256, 256, 1))\n",
    "shared = Conv2D(32, 3, activation='relu')(model_input)\n",
    "shared = Flatten()(shared)\n",
    "y1 = Dense(32, activation='relu')(shared)\n",
    "y1 = Dense(2, name='tb1')(y1)\n",
    "\n",
    "y2 = Dense(32, activation='relu')(shared)\n",
    "y2 = Dense(2, name='pneumonia')(y2)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "\n",
    "loss_list =[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)]\n",
    "test_metrics = {'tb1': 'accuracy', 'pneumonia': 'accuracy' }\n",
    "model.compile(loss=loss_list,optimizer='adam',metrics=test_metrics)\n",
    "\n",
    "\n",
    "model.fit(x_train, [y_train_tb1, y_train_p], batch_size=8, epochs=30)\n",
    "\n",
    "print(\"Evaluation: \")\n",
    "print(model.metrics_names)\n",
    "model.evaluate(x_test, [y_test_tb1, y_test_p], batch_size=8)\n",
    "\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[57  7]\n",
      " [13 56]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[242  54]\n",
      " [ 35 840]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions_tb1 = np.array(tf.argmax(predictions[0], axis=1))\n",
    "predictions_p = np.array(tf.argmax(predictions[1], axis=1))\n",
    "\n",
    "# only look at indices for ones with relevant data  \n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test_tb1[indices_test_tb1], predictions_tb1[indices_test_tb1], 2)\n",
    "print(cm)\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test_p[indices_test_p], predictions_p[indices_test_p], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
